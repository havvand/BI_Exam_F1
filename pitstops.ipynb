{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitstops and their Impact on Race Outcome\n",
    "We will be exploring pitstop data from F1 seasons 2018-2023 and looking at how they determine the outcome of the races\n",
    "\n",
    "## STEP 1 - Loading the Data & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start by importing the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "# Load the datasets\n",
    "races = pd.read_csv('data/races.csv')\n",
    "results = pd.read_csv('data/results.csv')\n",
    "pit_stops = pd.read_csv('data/pit_stops.csv', dtype={'milliseconds': 'int'})\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "races.head(), results.head(), pit_stops.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 - Filtering the Data\n",
    "We are only interested in data from seasons 2018-2023 so let us try to filter the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset for years 2018 to 2023\n",
    "races_2018_2023 = races[(races['year'] >= 2018) & (races['year'] <= 2023)]\n",
    "# Dropping unnecessary columns\n",
    "races_2018_2023.drop(columns=['fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', 'fp3_date', 'fp3_time', 'quali_date', 'quali_time', 'sprint_date', 'sprint_time', 'url'], inplace=True)\n",
    "\n",
    "# Getting the raceId for the years 2018 to 2023\n",
    "raceIds_2018_2023 = races_2018_2023['raceId'].unique()\n",
    "\n",
    "# Filtering pit_stops & results dataset with the raceIds from 2018 to 2023\n",
    "pit_stops_2018_2023 = pit_stops[pit_stops['raceId'].isin(raceIds_2018_2023)]\n",
    "results_2018_2023 = results[results['raceId'].isin(raceIds_2018_2023)]\n",
    "\n",
    "# Display the shape of the filtered datasets\n",
    "races_2018_2023.shape, pit_stops_2018_2023.shape, results_2018_2023.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 - Cleaning the Datasets\n",
    "Now that we have the filtered data we can carry on with cleaning the data by handling missing values and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the filtered datasets\n",
    "missing_values_races = races_2018_2023.isnull().sum()\n",
    "missing_values_results = results_2018_2023.isnull().sum()\n",
    "missing_values_pit_stops = pit_stops_2018_2023.isnull().sum()\n",
    "\n",
    "missing_values_races, missing_values_results, missing_values_pit_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values, however some have been filled with '/N' indicating a null value. Normally we would have to inspect, replace or in some instances remove those from out dataset because they could skew the analysis in many ways, but in this instance we're keeping them because for the datasets in question they signify that the racer has dropped out of the race for various reasons. Alternatively we could replace them with a numerical value for further analysis such as drop out percentage etc.\n",
    "\n",
    "Let us visualize the data in the form of histograms, boxplots and scatterplots to help further our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the descriptive statistics of the filtered datasets\n",
    "pit_stops_2018_2023.describe(), results_2018_2023.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Histogram for Lap Distribution in Pit Stops\n",
    "sns.histplot(pit_stops_2018_2023['lap'], bins=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most drivers have a pit stop around the first two laps. This can be caused by faulty equipment, accidents or a change in strategy.\n",
    "\n",
    "Apart from the first two laps the data shows signs of normal distribution. We can overlay the normal distribution curve to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(pit_stops_2018_2023['lap'], kde=False, stat=\"density\", bins=30, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Overlay the normal distribution curve\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = stats.norm.pdf(x, np.mean(pit_stops_2018_2023['lap']), np.std(pit_stops_2018_2023['lap']))\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "plt.title('Histogram of Lap Distribution in Pit Stops with Normal Distribution Curve')\n",
    "plt.xlabel('Lap Number')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at how the milliseconds, meaning the duration of the stops in ms is distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(pit_stops_2018_2023['milliseconds'], bins=150)\n",
    "plt.xlim([10000, 100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='milliseconds', data=pit_stops_2018_2023)\n",
    "plt.xlim([10000, 100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for Pit Stop Duration vs Lap Number\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=pit_stops_2018_2023, x='lap', y='milliseconds')\n",
    "plt.title('Scatter Plot of Pit Stop Duration vs Lap Number')\n",
    "plt.xlabel('Lap Number')\n",
    "plt.ylabel('Pit Stop Duration (milliseconds)')\n",
    "plt.ylim(10000, 100000)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the median pit stop duration\n",
    "median_pit_stop = pit_stops_2018_2023['milliseconds'].median()\n",
    "median_pit_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the boxplot that pitstops above 40.000 ms are considered outliers. The outliers are however better visualized in the scatterplot were we can determine that anything above 50.000 ms is a more precise way to determine what are outliers. That's a duration of 50 seconds for a pitstop, which is unusually long especially considering the median is around 23 seconds.\n",
    "So let us proceed with removing pitstops above 50.000 ms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers from the pit stop dataset anything above 50,000 milliseconds\n",
    "pit_stops_2018_2023 = pit_stops_2018_2023[pit_stops_2018_2023['milliseconds'] <= 50000]\n",
    "\n",
    "# removing time column from the pit stops dataset\n",
    "pit_stops_2018_2023.drop(columns=['time'], inplace=True)\n",
    "\n",
    "# Checking the descriptive statistics of the pit stops dataset\n",
    "pit_stops_2018_2023.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us merge the data from pit stops and results into one dataset and choose the columns we want to investigate further to see if there is basis for making predictions on outcome or otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets based on raceId and driverId\n",
    "merged_data = pd.merge(results_2018_2023, pit_stops_2018_2023, on=['raceId', 'driverId'])\n",
    "\n",
    "# rename milliseconds_x to milliseconds_lap and milliseconds_y to milliseconds_pit\n",
    "merged_data.rename(columns={'milliseconds_x': 'milliseconds_lap', 'milliseconds_y': 'milliseconds_pit'}, inplace=True)\n",
    "\n",
    "# Select relevant columns for further analysis\n",
    "relevant_columns = ['raceId', 'driverId', 'stop', 'lap', 'milliseconds_pit', 'positionOrder', 'points', 'laps']\n",
    "merged_data = merged_data[relevant_columns]\n",
    "\n",
    "# Display the merged dataset\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged dataset to a csv file\n",
    "merged_data.to_csv('data/merged_data.csv', index=False)\n",
    "# Descriptive statistics of the merged dataset\n",
    "merged_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the relationship between the different variables we will calculate the correlation matrix and visualize it in a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of the merged dataset\n",
    "correlation_matrix = merged_data.corr()\n",
    "\n",
    "# Heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Heatmap of Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can observe a slight correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between pit stop duration and race position\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='milliseconds_pit', y='positionOrder', data=merged_data)\n",
    "plt.ylim(1, 10)\n",
    "plt.title('Pit Stop Duration vs. Race Position')\n",
    "plt.xlabel('Pit Stop Duration (milliseconds)')\n",
    "plt.ylabel('Race Position (Order)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we can gather there is no significant correlation between pit stop duration and the outcome of the race. For exam related purpose I will try to build a predictive model to forecast the race outcome using all the data. For this I will use the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Select features and target variable\n",
    "features = merged_data[['driverId', 'stop', 'lap', 'milliseconds_pit', 'points', 'laps']]\n",
    "target = merged_data['positionOrder']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict race positions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display accuracy and classification report\n",
    "accuracy, report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5924882629107981"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display accuracy\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        67\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       1.00      1.00      1.00        61\n",
      "           4       1.00      1.00      1.00        55\n",
      "           5       1.00      1.00      1.00        52\n",
      "           6       1.00      0.98      0.99        53\n",
      "           7       0.98      1.00      0.99        50\n",
      "           8       1.00      0.98      0.99        65\n",
      "           9       0.98      1.00      0.99        45\n",
      "          10       1.00      1.00      1.00        52\n",
      "          11       0.11      0.13      0.12        52\n",
      "          12       0.14      0.11      0.12        64\n",
      "          13       0.16      0.16      0.16        62\n",
      "          14       0.15      0.15      0.15        66\n",
      "          15       0.21      0.31      0.25        51\n",
      "          16       0.20      0.15      0.17        61\n",
      "          17       0.15      0.14      0.15        56\n",
      "          18       0.13      0.11      0.12        56\n",
      "          19       0.19      0.30      0.23        27\n",
      "          20       0.36      0.22      0.27        23\n",
      "\n",
      "    accuracy                           0.59      1065\n",
      "   macro avg       0.59      0.59      0.59      1065\n",
      "weighted avg       0.59      0.59      0.59      1065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report indicates that the model is highly precise and accurate in predicting the higher positions (positions 1 to 10), but it struggles significantly with predicting the lower positions (positions 11 to 20)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
